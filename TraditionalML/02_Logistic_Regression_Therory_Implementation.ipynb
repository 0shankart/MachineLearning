{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classification and Logistic Regression"
      ],
      "metadata": {
        "id": "Q7t-ZnAor2Y4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets now talk about the classification problem. This is just like the regression problem, except that the vlaues y are now want to predict take on only a small number of discrete values. For now, we will focus on the **binary classification** problem in which y can take on two values, 0 and 1. (Most of what this notebook say here will also generalize to the multiple-class case). For instance, if we are trying to build a spam classifier for email, then $x^{(i)}$ may be some features of a piece of email, and $y$ may be 1 if it is a piece of spam mail, and 0 otherwise. 0 is called **negative class**, and 1 the **positive class**, they are sometimes also denoted by the symbols \"$-$\" and \"$+$\". Given $x^{(i)}$, the corresponding $y^{(i)}$ is also called the **label** for the training example."
      ],
      "metadata": {
        "id": "Mkk_WXMyr5x3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSOWD99gpu3z",
        "outputId": "050e4fc8-4240-4cd2-ae4c-f2d8f9c40c52"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQlZAqTmqFSl",
        "outputId": "cba9bfb6-4f72-4a98-b665-8574c4c65680"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (12.0, 9.0)"
      ],
      "metadata": {
        "id": "d_767We6qGkj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"iris.csv\")\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "F4d6s6TzqJWB",
        "outputId": "768cac68-c0fa-48ac-f9fb-4728f13b1972"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width            class\n",
              "0           6.6          2.9           4.6          1.3  Iris-versicolor\n",
              "1           5.7          3.8           1.7          0.3      Iris-setosa\n",
              "2           5.1          3.8           1.6          0.2      Iris-setosa\n",
              "3           5.5          3.5           1.3          0.2      Iris-setosa\n",
              "4           6.3          2.5           4.9          1.5  Iris-versicolor"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ffceafd-ffa4-450d-a523-5198e6a664b5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.6</td>\n",
              "      <td>2.9</td>\n",
              "      <td>4.6</td>\n",
              "      <td>1.3</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.9</td>\n",
              "      <td>1.5</td>\n",
              "      <td>Iris-versicolor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ffceafd-ffa4-450d-a523-5198e6a664b5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3ffceafd-ffa4-450d-a523-5198e6a664b5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3ffceafd-ffa4-450d-a523-5198e6a664b5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f9dcb982-bce7-4977-84b5-948922e59180\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9dcb982-bce7-4977-84b5-948922e59180')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f9dcb982-bce7-4977-84b5-948922e59180 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['class'].unique()"
      ],
      "metadata": {
        "id": "MeF7_XZhqP6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we are working on the logistic regression and where the target variable $\\in \\{0, 1\\}$, its better to convert the class variable to the"
      ],
      "metadata": {
        "id": "Y8jjXkAwqiy_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.1 Logistic regression"
      ],
      "metadata": {
        "id": "6oLT82iLvMzE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could approach the classification problem ignoring the fact that $y$ is discrete-valued, and use old linear regression algorithm to try to predict $y$ given $x$. However, it is easy to construct examlpes where this method performs very poorly. Intuitively, it also deosn't make sense for $h_\\theta(x)$ to take values larger than 1 or smaller than 0 when we know that $ y \\in \\{0, 1\\}$.\n",
        "\n",
        "To fix this, let's change the form for our hypothesis $h_\\theta(x)$. We will choose\n",
        "$$h_\\theta(x) = g(\\theta^Tx) = \\frac{1}{1 + e^{-\\theta^Tx}},$$\n",
        "where\n",
        "$$g(z) = \\frac{1}{1+e^{-z}}$$\n",
        "is called the **logistic function** or the **sigmoid function**. Here is a plot showing $g(z)$:\n",
        "<figure>\n",
        "  <img src=\"TraditionalML/images/sigmoid_activation_function.png\" width=\"40%\"/>\n",
        "  <figcaption>Ref: https://cs229.stanford.edu/notes2021fall/cs229-notes1.pdf</figcaption>\n",
        "</figure>\n",
        " <br>\n",
        "\n",
        "Notice that $g(z)$ tends towards 1 as $z \\to \\infty$, and $g(z)$ tends towards $0$ as $z \\to -\\infty$. Moreover, $g(z)$, and hence also $h(x)$, is always bounded between $0$ and $1$. As before, we are keeping the convention of letting $x_0 = 1$, so that $ \\theta^Tx = \\theta_0 + \\sum_{j=1}^d\\theta_jx_j$.<br>\n",
        "\n",
        "For now, let's take the choice of $g$ as given. Other functions that smoothly increase from $0$ to $1$ can also be used, but for a couple of reasons that we'll see later( when we talk about GLMs, and when we talk about generative learning algorithms), the choice of the logistic function is a fairly natural one. Before moving on, here's a useful property of the derivative of the signmoid fucntion, which we write as $g'$:<br>\n",
        "\n",
        "$$\\begin{align*}g'(z) &= \\frac{d}{dz}\\frac{1}{1 + e^{-z}} \\\\\n",
        "&= \\frac{1}{(1 + e^{-z})^2}(e^{-z}) \\\\\n",
        "&= \\frac{1}{(1 + e^{-z})}.\\left(1 - \\frac{1}{(1 + e^{-z})}\\right)\\end{align*}$$\n",
        "\n",
        " So, given the logistic regression model, how do we fit $\\theta$ for it? Following how we saw least squares regression could be derived as the maximum like-lihood estimator under a set of assumptions, let's endow our classficitiona model with a set of probabilistc assumptions, lets endow our classifiction model with a set of probabilistic assumptions, and then fit the parameters via maximum likelihood. <br>\n",
        "\n",
        " Let us assume that\n",
        " $$\\begin{align*}\n",
        " P(Y = 1 | x; \\theta) &= h_\\theta(x) \\\\\n",
        " P(Y = 0 | x; \\theta) &= 1 - h_\\theta(x)\n",
        " \\end{align*}$$\n",
        "\n",
        " <br>Note that thsi can be written more compactly as<br>\n",
        " $$\\begin{align*}\n",
        " p(y | x;\\theta) = (h_\\theta(x))^y (1 - h_\\theta(x))^{1-y}\n",
        " \\end{align*}$$\n",
        " <br>\n",
        " Assuming that the $n$ traininig examples were generated independently, we can then write down the likelihood of the parameters as\n",
        " $$\\begin{align*}\n",
        " L(\\theta) &= p(\\vec{y}| X;\\theta) \\\\\n",
        " &= \\prod_{i=1}^np(y^{(i)} | x^{(i)}; \\theta) \\\\\n",
        " &= \\prod_{i=1}^np(h_\\theta(x^{(i)}))^{y^{(i)}}(1 - h_\\theta(x^{(i)}))^{1 - y^{(i)}}\n",
        "\\end{align*}$$\n",
        "\n",
        "As before, it will be easier to maximize the log likelihood:\n",
        "$$\\begin{align*}\n",
        "l(\\theta) &= \\text{log} L(\\theta) \\\\\n",
        "&= \\sum_{i=n}^ny^{(i)}\\text{log}h(x^{(i)}) + (1 - y^{(i)})\\text{log}(1 - h(x^{(i)}))\n",
        "\\end{align*}$$\n",
        "\n",
        "How do we maximize the likelihood? Similar to our derivation in the case of linear regression, we can use gradient ascent. Written in vectorial notation, our update will therefore be given by $ \\theta := \\theta + \\alpha\\Delta_\\theta l(\\theta)$. (Note the positive rather than negative sign in the update formula, since we'are maximizing, rather than minimizing, a function now.) Let's start by working with just one training examle $(x,y)$, and take derivatives to derive the stochastic gradient ascent rule:\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\frac{\\partial}{\\partial \\theta_j} l(\\theta) &= \\left( y \\frac{1}{g(\\theta^Tx)} - (1-y)\\frac{1}{1-g(\\theta^Tx)}  \\right)\\frac{\\partial}{\\theta_j}g(\\theta^Tx)\\\\\n",
        "&= \\left( y \\frac{1}{g(\\theta^Tx)} - (1-y)\\frac{1}{1-g(\\theta^Tx)}  \\right) g(\\theta^Tx)(1 - g(\\theta^Tx))\\frac{\\partial}{\\partial \\theta_j}\\theta^Tx \\\\\n",
        "&= (y(1 - g(\\theta^Tx)) - (1-y)g(\\theta^Tx))x_j \\\\\n",
        "&=(y -h\\theta(x))x_j\n",
        "\\end{align*}$$\n",
        "<br>\n",
        "Above, we used the fact that $g'(z) = g(z)(1-g(z))$. This therefore gives us the stochastic gradient ascent rule:\n",
        "$$ \\theta_j := \\theta_j + \\alpha(y^{(i)} - h_\\theta(x^{(i)}))x_j^{(i)}$$\n",
        "<br>\n",
        "If we compare this to the LMS update rule, we that it looks identical; but this $\\textit{not}$ the same algorithm, becuase $h_\\theta(x^{(i)})$ is now defined as a non-linear function of $\\theta^Tx^{(i)}$. Nonetheless, its a little suprising that we end up with the same update rule for a rather different algorithm and learning problem.\n",
        "\n",
        "$\\cdots \\vdots \\ddots$"
      ],
      "metadata": {
        "id": "axQHQvc4vX7k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oapaZ457qoOO"
      },
      "outputs": [],
      "source": []
    }
  ]
}
